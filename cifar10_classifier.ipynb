{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Kf9YVOkpXL1h"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import numpy as np\n",
        "from torchvision import datasets\n",
        "from torchvision import transforms\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import random_split\n",
        "from torch.utils.data.dataloader import DataLoader\n",
        "from torchvision.datasets.utils import download_url\n",
        "import os\n",
        "import tarfile\n",
        "import datetime\n",
        "from torchvision.datasets import ImageFolder\n",
        "from torchvision.transforms import ToTensor\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "matplotlib.rcParams['figure.facecolor'] = '#ffffff'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v_-d0_PZPzC7",
        "outputId": "c746e888-0ec2-4df8-d7a1-2e94799fb87a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using downloaded and verified file: ./cifar10.tgz\n"
          ]
        }
      ],
      "source": [
        "dataset_url = \"https://s3.amazonaws.com/fast-ai-imageclas/cifar10.tgz\"\n",
        "download_url(dataset_url, '.')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hXJ4jQfJP-GS"
      },
      "outputs": [],
      "source": [
        "with tarfile.open('./cifar10.tgz', 'r:gz') as tar:\n",
        "    tar.extractall(path='./data')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QsMX7BZxP-k0",
        "outputId": "64af7db6-104e-4603-81b5-aab71e584f6a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['test', 'train']\n",
            "['frog', 'truck', 'dog', 'ship', 'deer', 'airplane', 'bird', 'cat', 'horse', 'automobile']\n"
          ]
        }
      ],
      "source": [
        "data_dir = './data/cifar10'\n",
        "\n",
        "print(os.listdir(data_dir))\n",
        "classes = os.listdir(data_dir + \"/train\")\n",
        "print(classes)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mI_tL0YCQK50",
        "outputId": "2b024131-c7d8-4f3f-ce49-4031affaab4e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "No. of training examples for airplanes: 5000\n",
            "['1001.png', '3558.png', '0591.png', '1855.png', '4396.png']\n"
          ]
        }
      ],
      "source": [
        "airplane_files = os.listdir(data_dir + \"/train/airplane\")\n",
        "print('No. of training examples for airplanes:', len(airplane_files))\n",
        "print(airplane_files[:5])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QLSQHuqEQLbC",
        "outputId": "561b0638-1870-4f8d-bd94-d0751173ae75"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "No. of test examples for ship: 1000\n",
            "['0591.png', '0761.png', '0939.png', '0410.png', '0110.png']\n"
          ]
        }
      ],
      "source": [
        "ship_test_files = os.listdir(data_dir + \"/test/ship\")\n",
        "print(\"No. of test examples for ship:\", len(ship_test_files))\n",
        "print(ship_test_files[:5])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XLVdof-kQXpT"
      },
      "outputs": [],
      "source": [
        "cifar10 = ImageFolder(data_dir+'/train', transform=ToTensor())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jhW8nLk5QqQQ"
      },
      "outputs": [],
      "source": [
        "def show_example(img, label):\n",
        "    print('Label: ', cifar10.classes[label], \"(\"+str(label)+\")\")\n",
        "    plt.imshow(img.permute(1, 2, 0))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HOXJDQFxYFNC",
        "outputId": "14c2cd13-3da3-4855-a75c-f731e1cac8b0"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "50000"
            ]
          },
          "execution_count": 81,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(cifar10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WD23AArbYtpv"
      },
      "outputs": [],
      "source": [
        "img, label = cifar10[99]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sIFhdKkn_7Mt",
        "outputId": "f3fe64e7-9351-4f0c-ee6a-ea3065a58b61"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7f09ba08bad0>"
            ]
          },
          "execution_count": 83,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "random_seed = 42\n",
        "torch.manual_seed(random_seed)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fcSj3ws_AHMA",
        "outputId": "8765282e-b275-4e0d-8945-96d818a8d7d0"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(45000, 5000)"
            ]
          },
          "execution_count": 84,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "val_size = 5000\n",
        "train_size = len(cifar10) - val_size\n",
        "train_ds,val_ds = random_split(cifar10, [train_size, val_size])\n",
        "len(train_ds), len(val_ds)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DZdAbRmJqwsY",
        "outputId": "e10f5625-6164-4ae7-a572-afeb2e1845d4"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n"
          ]
        }
      ],
      "source": [
        "batch_size = 128\n",
        "train_dl = DataLoader(train_ds, batch_size, shuffle=True, num_workers=4, pin_memory=True)\n",
        "val_dl = DataLoader(val_ds, batch_size*2, num_workers=4, pin_memory=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x-omjo3BSCut"
      },
      "outputs": [],
      "source": [
        "class ImageClassificationBase(nn.Module) :\n",
        "  def training_step(self, batch) : \n",
        "    images, labels = batch\n",
        "    out = self(images)\n",
        "    loss = F.cross_entropy(out, labels)\n",
        "    return loss\n",
        "  \n",
        "  def validation_step(self, batch) :\n",
        "    images, labels = batch\n",
        "    out = self(images)\n",
        "    loss = F.cross_entropy(out, labels)\n",
        "    acc = accuracy(out, labels)\n",
        "    return {'val_loss' : loss.detach(), 'val_acc' : acc}\n",
        "\n",
        "  def validation_epoch_end(self, outputs) :\n",
        "    batch_losses = [x['val_loss'] for x in outputs]\n",
        "    epoch_loss = torch.stack(batch_losses).mean()\n",
        "    batch_accs = [x['val_acc'] for x in outputs]\n",
        "    epoch_acc = torch.stack(batch_accs).mean()\n",
        "    return {'val_loss' : epoch_loss.item(), 'val_acc' : epoch_acc.item()}\n",
        "\n",
        "  def epoch_end(self, epoch, result) :\n",
        "    print(\"Epoch [{}], train_loss: {:.4f}, val_loss: {:.4f}, val_acc: {:.4f}\".format(epoch, result['train_loss'], result['val_loss'], result['val_acc']))\n",
        "\n",
        "def accuracy(outputs, labels) :\n",
        "  _ , preds = torch.max(outputs, dim = 1)\n",
        "  return torch.tensor(torch.sum(preds == labels).item() / len(preds))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mslwq0RefZAg"
      },
      "outputs": [],
      "source": [
        "class Cifar10CnnModel(ImageClassificationBase): \n",
        "  def __init__(self) :\n",
        "    super().__init__()\n",
        "    self.network = nn.Sequential(\n",
        "        nn.Conv2d(3,32, kernel_size = 3 , padding = 1),\n",
        "        nn.ReLU(),\n",
        "        nn.Conv2d(32, 64, kernel_size = 3, stride = 1, padding = 1),\n",
        "        nn.ReLU(),\n",
        "        nn.MaxPool2d(2, 2),\n",
        "\n",
        "        nn.Conv2d(64, 128, kernel_size = 3, stride = 1, padding = 1),\n",
        "        nn.ReLU(),\n",
        "        nn.Conv2d(128, 128, kernel_size = 3, stride = 1, padding = 1),\n",
        "        nn.ReLU(),\n",
        "        nn.MaxPool2d(2, 2),\n",
        "\n",
        "        nn.Conv2d(128, 256, kernel_size = 3 , stride = 1, padding = 1),\n",
        "        nn.ReLU(),\n",
        "        nn.Conv2d(256, 256, kernel_size = 3, stride = 1, padding = 1),\n",
        "        nn.ReLU(),\n",
        "        nn.MaxPool2d(2, 2),\n",
        "\n",
        "        nn.Flatten(),\n",
        "        nn.Linear(256*4*4, 1024),\n",
        "        nn.ReLU(),\n",
        "        nn.Linear(1024,512),\n",
        "        nn.ReLU(),\n",
        "        nn.Linear(512, 10))\n",
        "    \n",
        "  def forward(self, xb):\n",
        "    return self.network(xb)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e0tkixxWp43_",
        "outputId": "7d869222-7b90-4324-b95a-482239c82656"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Cifar10CnnModel(\n",
              "  (network): Sequential(\n",
              "    (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (1): ReLU()\n",
              "    (2): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (3): ReLU()\n",
              "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (6): ReLU()\n",
              "    (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (8): ReLU()\n",
              "    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (11): ReLU()\n",
              "    (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (13): ReLU()\n",
              "    (14): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (15): Flatten(start_dim=1, end_dim=-1)\n",
              "    (16): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "    (17): ReLU()\n",
              "    (18): Linear(in_features=1024, out_features=512, bias=True)\n",
              "    (19): ReLU()\n",
              "    (20): Linear(in_features=512, out_features=10, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "execution_count": 88,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model  = Cifar10CnnModel()\n",
        "model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l_RUn1MXupgF",
        "outputId": "758cd96a-d1ea-4c41-f925-aea56fdd8a76"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 89,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "torch.cuda.is_available()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NrgsxZWjq4KT"
      },
      "outputs": [],
      "source": [
        "def get_default_device() :\n",
        "  if torch.cuda.is_available() :\n",
        "    return torch.device('cuda')\n",
        "  else :\n",
        "    return torch.device('cpu')\n",
        "def to_device(data, device) :\n",
        "  if isinstance(data, (list,tuple)) :\n",
        "    return [to_device(x,device) for x in data]\n",
        "  return data.to(device, non_blocking = True)\n",
        "\n",
        "class DeviceDataLoader() :\n",
        "  def __init__(self, dl, device) :\n",
        "    self.dl = dl\n",
        "    self.device = device\n",
        "  \n",
        "  def __iter__(self) :\n",
        "    for b in self.dl :\n",
        "      yield to_device(b, self.device)\n",
        "\n",
        "  def __len__(self) :\n",
        "    return len(self.dl)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "McstXPYsvTBc",
        "outputId": "565fa407-c088-4071-b56b-bc7af0493b87"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "device(type='cuda')"
            ]
          },
          "execution_count": 91,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "device = get_default_device()\n",
        "device"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MTIbqrM_vcco"
      },
      "outputs": [],
      "source": [
        "train_dl = DeviceDataLoader(train_dl, device)\n",
        "val_dl = DeviceDataLoader(val_dl, device)\n",
        "to_device(model, device);"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3MD9z1LW1wFm"
      },
      "outputs": [],
      "source": [
        "@torch.no_grad()\n",
        "def evaluate(model, val_loader):\n",
        "    model.eval()\n",
        "    outputs = [model.validation_step(batch) for batch in val_loader]\n",
        "    return model.validation_epoch_end(outputs)\n",
        "\n",
        "def fit(epochs, lr, model, train_loader, val_loader, opt_func=torch.optim.SGD):\n",
        "    history = []\n",
        "    optimizer = opt_func(model.parameters(), lr)\n",
        "    for epoch in range(epochs):\n",
        "        # Training Phase \n",
        "        model.train()\n",
        "        train_losses = []\n",
        "        for batch in train_loader:\n",
        "            loss = model.training_step(batch)\n",
        "            train_losses.append(loss)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            optimizer.zero_grad()\n",
        "        # Validation phase\n",
        "        result = evaluate(model, val_loader)\n",
        "        result['train_loss'] = torch.stack(train_losses).mean().item()\n",
        "        model.epoch_end(epoch, result)\n",
        "        history.append(result)\n",
        "    return history"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qytaKFmN6vGk"
      },
      "outputs": [],
      "source": [
        "model = to_device(Cifar10CnnModel(), device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NkL2cZymJg7I"
      },
      "outputs": [],
      "source": [
        "num_epochs = 30\n",
        "opt_func = optim.Adam\n",
        "lr = 0.001"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CBAEIyWwmO2c",
        "outputId": "f83c7926-dbac-41c9-9fa2-3a4eb88a5deb"
      },
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [0], train_loss: 1.9173, val_loss: 1.6427, val_acc: 0.3873\n",
            "Epoch [1], train_loss: 1.5302, val_loss: 1.4780, val_acc: 0.4518\n",
            "Epoch [2], train_loss: 1.3986, val_loss: 1.3508, val_acc: 0.5064\n",
            "Epoch [3], train_loss: 1.2955, val_loss: 1.2748, val_acc: 0.5473\n",
            "Epoch [4], train_loss: 1.2055, val_loss: 1.1637, val_acc: 0.5749\n",
            "Epoch [5], train_loss: 1.1252, val_loss: 1.0992, val_acc: 0.6106\n",
            "Epoch [6], train_loss: 1.0617, val_loss: 1.0813, val_acc: 0.6126\n",
            "Epoch [7], train_loss: 0.9860, val_loss: 1.0247, val_acc: 0.6303\n",
            "Epoch [8], train_loss: 0.9271, val_loss: 0.9840, val_acc: 0.6539\n",
            "Epoch [9], train_loss: 0.8711, val_loss: 0.9063, val_acc: 0.6861\n",
            "Epoch [10], train_loss: 0.8124, val_loss: 0.8891, val_acc: 0.6921\n",
            "Epoch [11], train_loss: 0.7613, val_loss: 0.8418, val_acc: 0.7122\n",
            "Epoch [12], train_loss: 0.7123, val_loss: 0.8510, val_acc: 0.7028\n",
            "Epoch [13], train_loss: 0.6647, val_loss: 0.8367, val_acc: 0.7127\n",
            "Epoch [14], train_loss: 0.6207, val_loss: 0.7880, val_acc: 0.7346\n",
            "Epoch [15], train_loss: 0.5643, val_loss: 0.7824, val_acc: 0.7396\n",
            "Epoch [16], train_loss: 0.5102, val_loss: 0.8083, val_acc: 0.7364\n",
            "Epoch [17], train_loss: 0.4614, val_loss: 0.8264, val_acc: 0.7343\n",
            "Epoch [18], train_loss: 0.4103, val_loss: 0.8498, val_acc: 0.7405\n",
            "Epoch [19], train_loss: 0.3513, val_loss: 0.9177, val_acc: 0.7338\n"
          ]
        }
      ],
      "source": [
        "history = fit(num_epochs, lr, model , train_dl, val_dl, opt_func)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "cifar10 classifier.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}